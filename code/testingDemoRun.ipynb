{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9a442cf",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56fa3e2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/w_/wd9692011gs08kcd4t4qmtpr0000gn/T/ipykernel_93595/3908266745.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mseaborn\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0msb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import time\n",
    "# import mat4py\n",
    "import scipy.io \n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import plotly.express as px\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans \n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.signal import lfilter,butter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install antropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import antropy as ant\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "# from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0297521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa72481",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f8406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41bae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0565aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_signal_filename = 'Dataset1.mat'\n",
    "attack_signal_filename = 'sampleAttack.mat'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a438a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_realsignal_from_path(fpath):\n",
    "    mat = scipy.io.loadmat(fpath)\n",
    "    raw_data = mat['Raw_Data']\n",
    "    total_rows = []\n",
    "    for i in range(raw_data.shape[0]):\n",
    "        for j in range(raw_data.shape[1]):\n",
    "            total_rows.extend(np.array_split(raw_data[i][j], 4))\n",
    "    raw_df = pd.DataFrame(total_rows)\n",
    "    return raw_df\n",
    "\n",
    "def load_attacksignal_from_path(fpath):\n",
    "    mat = scipy.io.loadmat(fpath)\n",
    "    raw_data = mat['attackVectors']\n",
    "    total_rows = []\n",
    "    for i in range(raw_data.shape[0]):\n",
    "        for j in range(raw_data.shape[1]):\n",
    "            for k in range(raw_data.shape[2]):\n",
    "                total_rows.append(raw_data[i][j][k])\n",
    "    raw_df = pd.DataFrame(total_rows)\n",
    "    return raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = load_realsignal_from_path(real_signal_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1149f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_df = load_attacksignal_from_path(attack_signal_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ebd0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965786b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9af75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d87d5e27",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e89fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_norm(df):\n",
    "    x = df.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df_minmax = pd.DataFrame(x_scaled)\n",
    "    return df_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aecbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_norm(df):\n",
    "    x = df.values\n",
    "    std_scaler = preprocessing.StandardScaler()\n",
    "    x_scaled = std_scaler.fit_transform(x)\n",
    "    df_std = pd.DataFrame(x_scaled)\n",
    "    return df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20097275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd3b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_superset = pd.concat( [std_norm(real_df), std_norm(attack_df)] , axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b883408",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_superset = [1.0 for i in range(len(real_df)) ]\n",
    "y_superset.extend([0.0 for i in range(len(attack_df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac35a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "094cba88",
   "metadata": {},
   "source": [
    "# Test Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cded47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_superset, y_superset, test_size=0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b4209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5572117",
   "metadata": {},
   "source": [
    "# Features extraction list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febc9c09",
   "metadata": {},
   "source": [
    "Features: PCA, Entropy, FFT Theta band, Bio Orthogonal Family, TF-IDF\n",
    "\n",
    "models: SVM, Cosine, Kmeans, KNN, CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a3b08",
   "metadata": {},
   "source": [
    "## PCA feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_count = 100\n",
    "pca = decomposition.PCA(n_components = best_feature_count) # only keep two \"best\" features!\n",
    "X_train_pca = pca.fit_transform(X_train) # apply PCA to the train data\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1a3802",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0664291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_features(X):\n",
    "    res_data=[]\n",
    "    for i in range(len(X)):\n",
    "        x = X[i]\n",
    "                \n",
    "        perm = ant.perm_entropy(x, normalize=True)\n",
    "        spectral = ant.spectral_entropy(x, sf=160, method='welch', normalize=True)\n",
    "        svd = ant.svd_entropy(x, normalize=True)\n",
    "        approx = ant.app_entropy(x)\n",
    "        sample = ant.sample_entropy(x)\n",
    "        temp_ans = [perm, spectral, svd, approx, sample]\n",
    "        res_data.append(temp_ans)\n",
    "    return res_data\n",
    "\n",
    "X_train_entropy = entropy_features(np.asarray(X_train))\n",
    "\n",
    "X_test_entropy = entropy_features(np.asarray(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f19176",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_entropy_array = np.asarray(X_train_entropy)\n",
    "X_test_entropy_array = np.asarray(X_test_entropy)\n",
    "\n",
    "X_test_entropy_array.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448d6287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2519dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e636f",
   "metadata": {},
   "source": [
    "## FFT theta band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87972b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut /nyq\n",
    "    high = highcut/nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    #print(b,a)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "temp = X_train.values\n",
    "temp1 = X_test.values\n",
    "\n",
    "X_train_theta = []\n",
    "for i in range(len(temp)):\n",
    "    \n",
    "    fft1 = fft (temp[i])\n",
    "    theta1 = butter_bandpass_filter(fft1, 4.1, 8.0, 160)\n",
    "    X_train_theta.append(theta1)\n",
    "\n",
    "X_test_theta = []\n",
    "for i in range(len(temp1)):\n",
    "    \n",
    "    fft1 = fft (temp1[i])\n",
    "    theta1 = butter_bandpass_filter(fft1, 4.1, 8.0, 160)\n",
    "    X_test_theta.append(theta1)\n",
    "\n",
    "X_train_theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fa2e95",
   "metadata": {},
   "source": [
    "## Bio orthogonal family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc48c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0ebaa7d",
   "metadata": {},
   "source": [
    "## TF -IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec21831",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = X_train.values.tolist() \n",
    "X_train_tfidf_rounded = []\n",
    "for i in range (len(X_train_tfidf)):\n",
    "    temp = []\n",
    "    for j in range (len(X_train_tfidf[i])):\n",
    "        a = round(X_train_tfidf[i][j],2)\n",
    "        temp.append (a)\n",
    "    X_train_tfidf_rounded.append(temp)\n",
    "\n",
    "X_train_tfidf_rounded_string = []\n",
    "for i in range (len(X_train_tfidf_rounded)):\n",
    "    temp = []\n",
    "    for j in range (len(X_train_tfidf_rounded[i])):\n",
    "        a = str(X_train_tfidf_rounded[i][j])\n",
    "        temp.append (a)\n",
    "    newtemp = \" \".join(temp)\n",
    "    X_train_tfidf_rounded_string.append(newtemp)\n",
    "\n",
    "\n",
    "# for i in range (len(X_train_tfidf)):\n",
    "#     X_tfidf_string = str (X_train_tfidf[i])\n",
    "# # documentA = 'the man went out for a walk'\n",
    "# # documentB = 'abcd'\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# vectors = vectorizer.fit_transform(X_train_tfidf)\n",
    "# feature_names = vectorizer.get_feature_names()\n",
    "# dense = vectors.todense()\n",
    "# denselist = dense.tolist()\n",
    "# df = pd.DataFrame (denselist, columns=feature_names)\n",
    "# cvec = CountVectorizer()\n",
    "# cvec_counts = cvec.fit_transform(X_train_tfidf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd71d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = X_test.values.tolist()\n",
    "X_test_tfidf_rounded = []\n",
    "for i in range (len(X_test_tfidf)):\n",
    "    temp = []\n",
    "    for j in range (len(X_test_tfidf[i])):\n",
    "        a = round(X_test_tfidf[i][j],2)\n",
    "        temp.append (a)\n",
    "    X_test_tfidf_rounded.append(temp)\n",
    " \n",
    "X_test_tfidf_rounded_string = []\n",
    "for i in range (len(X_test_tfidf_rounded)):\n",
    "    temp = []\n",
    "    for j in range (len(X_test_tfidf_rounded[i])):\n",
    "        a = str(X_test_tfidf_rounded[i][j])\n",
    "        temp.append (a)\n",
    "    newtemp = \" \".join(temp)\n",
    "    X_test_tfidf_rounded_string.append(newtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7f8217",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(X_test_tfidf_rounded_string)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "X_test_tfidffeatures = pd.DataFrame (denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d1c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(X_)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "X_train_tfidffeatures = pd.DataFrame (denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a271e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6006a01d",
   "metadata": {},
   "source": [
    "# Model Training section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c236e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b98a561",
   "metadata": {},
   "source": [
    "##  MLP Classifier (trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ae1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp = MLPClassifier( hidden_layer_sizes=(100), activation= 'relu', max_iter=1000, alpha=0.0001,\n",
    "                           solver= 'adam', tol=0.0001 ) #changed from logistic to relu for better output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640d600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp.fit(X_train_pca, y_train) #train the data using the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bfbfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_mlp.predict(X_test_pca) # predict the class of Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f0402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_mlp = accuracy_score(y_test, y_pred) #accuracy of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dce3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc443f61",
   "metadata": {},
   "source": [
    "## MLP Trial TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp.fit(X_train_tfidffeatures, y_train) #train the data using the MLP\n",
    "y_pred = model_mlp.predict(X_test_tfidffeatures) # predict the class of Testa\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred) #accuracy of test data\n",
    "\n",
    "accuracy_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c8e96",
   "metadata": {},
   "source": [
    "## Entropy Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0116da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp.fit(X_train_entropy_array, y_train) #train the data using the MLP\n",
    "y_pred = model_mlp.predict(X_test_entropy_array) # predict the class of Test\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred) #accuracy of test data\n",
    "accuracy_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b77999d",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdef9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = SVC(kernel='linear', C=1.0, random_state = 1 )\n",
    "model_svm.fit(X_train_pca, y_train)     # do the training\n",
    "y_pred2 = model_svm.predict(X_test_pca) # work on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872cfa2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aacd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_svm = accuracy_score(y_test, y_pred2) #accuracy of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46475703",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbb3a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e617827",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a50096",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors = 2)\n",
    "model_knn.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46179db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict Output\n",
    "y_pred3 = model_knn.predict(X_test_pca) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e4d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_knn = accuracy_score(y_test, y_pred3) #accuracy of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d894fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69e277a",
   "metadata": {},
   "source": [
    "## KNN Trial Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56208f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn_entropy = KNeighborsClassifier(n_neighbors = 4)\n",
    "model_knn_entropy.fit(X_train_entropy_array,y_train)\n",
    "#Predict Output\n",
    "y_pred3 = model_knn_entropy.predict(X_test_entropy_array) \n",
    "accuracy_knn = accuracy_score(y_test, y_pred3) #accuracy of test data\n",
    "accuracy_knn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7612ba1",
   "metadata": {},
   "source": [
    "## CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_evaluate(trainX, trainy, testX, testy):\n",
    "\tverbose, epochs, batch_size = 0, 10, 32\n",
    "\tn_timesteps, n_features, n_outputs = trainX.shape[0], trainX.shape[1], trainy.shape[0]\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(MaxPooling1D(pool_size=2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\t# evaluate model\n",
    "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\treturn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d8bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_array = np.asarray (y_train)\n",
    "# y_test_array = np.asarray (y_test)\n",
    "\n",
    "X_train_cnn = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "\n",
    "# cnn_accuracy = cnn_evaluate(X_train_pca.values, to_categorical(y_train_array), X_test_pca, to_categorical (y_test_array))\n",
    "\n",
    "# cnn_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f681fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X Train shape: \", X_train_cnn.shape)\n",
    "print(\"X Test shape: \", X_test_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697a6683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequential model \n",
    "cnn_model = tf.keras.models.Sequential()\n",
    "#First CNN layer  with 32 filters, conv window 3, relu activation and same padding\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001), input_shape = (X_train_cnn.shape[1],1)))\n",
    "#Second CNN layer  with 64 filters, conv window 3, relu activation and same padding\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "#Third CNN layer with 128 filters, conv window 3, relu activation and same padding\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "#Fourth CNN layer with Max pooling\n",
    "cnn_model.add(MaxPooling1D(pool_size=(3,), strides=2, padding='same'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "#Flatten the output\n",
    "cnn_model.add(Flatten())\n",
    "#Add a dense layer with 256 neurons\n",
    "cnn_model.add(Dense(units = 256, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "#Add a dense layer with 512 neurons\n",
    "cnn_model.add(Dense(units = 512, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "#Softmax as last layer with five outputs\n",
    "cnn_model.add(Dense(units = 2, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1181793",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd7d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cnn = to_categorical(y_train)\n",
    "y_test_cnn = to_categorical(y_test)\n",
    "cnn_model_history = cnn_model.fit(X_train_cnn, np.asarray (y_train), epochs=2, batch_size = 20 , validation_data = (X_test_cnn, np.asarray (y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9cad99",
   "metadata": {},
   "source": [
    "## K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf88c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = len(np.unique(y_train))\n",
    "kmeans_model = KMeans(n_clusters = n_clusters, random_state=42)\n",
    "kmeans_model.fit(X_train_pca)\n",
    "y_labels_train_knn = kmeans_model.labels_\n",
    "y_labels_test_knn = kmeans_model.predict(X_test_pca)\n",
    "\n",
    "# X_train['km_clust'] = y_labels_train\n",
    "# X_test['km_clust'] = y_labels_test\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "accuracy_kmeans = accuracy_score(y_train, y_labels_train_knn)\n",
    "\n",
    "accuracy_kmeans = accuracy_score (y_test, y_labels_test_knn)\n",
    "\n",
    "accuracy_kmeans \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c4a799",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e77145a",
   "metadata": {},
   "source": [
    "# Timepass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fa01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=real_df.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2cec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = attack_df.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf42a5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db1d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d57f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x_[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9b967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd518329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f6679",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ = scipy.io.loadmat('data/inputSample.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a1c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ = scipy.io.loadmat('data/input_attack.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a99b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1884a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd1 = [[1,2,3],[4,5,6]]\n",
    "sd2 = [[7,8]]\n",
    "sd1_df = pd.DataFrame(sd1)\n",
    "sd2_df = pd.DataFrame(sd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66302d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd1_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd2_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b5bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([sd1_df.transpose(), sd2_df.transpose()], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e70db77",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e81053e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}